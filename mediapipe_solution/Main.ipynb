{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import data, img_as_float\n",
    "from skimage import exposure\n",
    "\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c11e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        landmark_list[index][0] = np.abs(landmark_list[index][0] - base_x)\n",
    "        landmark_list[index][1] = np.abs(landmark_list[index][1] - base_y)\n",
    "\n",
    "    flattened = []\n",
    "    for i in range(landmark_list.shape[0]):\n",
    "        flattened.append(landmark_list[i][0])\n",
    "        flattened.append(landmark_list[i][1])\n",
    "\n",
    "\n",
    "    normalized = []\n",
    "    # Normalization\n",
    "    for i in range(len(flattened)):\n",
    "        normalized.append(flattened[i]/max(flattened))\n",
    "\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def csv(letter, landmark_list):\n",
    "    csv_path = 'keypoint.csv'\n",
    "    with open(csv_path, 'a', newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([*landmark_list, letter])\n",
    "    return\n",
    "\n",
    "def landmark_list(image, landmarks):\n",
    "    height, width = image.shape\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * width), width - 1)\n",
    "        landmark_y = min(int(landmark.y * height), height - 1)\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting the long part...\n",
      "dir A img ../customdata/A/A_0.jpg\n",
      "dir C img ../customdata/C/C_0.jpg\n",
      "dir E img ../customdata/E/E_0.jpg\n",
      "dir G img ../customdata/G/G_0.jpg\n",
      "dir I img ../customdata/I/I_0.jpg\n",
      "dir K img ../customdata/K/K_0.jpg\n",
      "dir M img ../customdata/M/M_0.jpg\n",
      "dir O img ../customdata/O/O_0.jpg\n",
      "dir Q img ../customdata/Q/Q_0.jpg\n",
      "dir S img ../customdata/S/S_0.jpg\n",
      "dir U img ../customdata/U/U_0.jpg\n",
      "dir W img ../customdata/W/W_0.jpg\n",
      "dir Y img ../customdata/Y/Y_0.jpg\n",
      "dir [ img ../customdata/[/del_0.jpg\n",
      "NO HANDS FOUND  1 ../customdata/]/space_156.jpg ]\n",
      "NO HANDS FOUND  2 ../customdata/]/space_157.jpg ]\n",
      "NO HANDS FOUND  3 ../customdata/]/space_159.jpg ]\n",
      "NO HANDS FOUND  4 ../customdata/]/space_160.jpg ]\n",
      "NO HANDS FOUND  5 ../customdata/]/space_161.jpg ]\n",
      "NO HANDS FOUND  6 ../customdata/]/space_163.jpg ]\n",
      "NO HANDS FOUND  7 ../customdata/]/space_164.jpg ]\n",
      "NO HANDS FOUND  8 ../customdata/]/space_346.jpg ]\n",
      "NO HANDS FOUND  9 ../customdata/]/space_349.jpg ]\n",
      "NO HANDS FOUND  10 ../customdata/]/space_350.jpg ]\n",
      "NO HANDS FOUND  11 ../customdata/]/space_351.jpg ]\n",
      "NO HANDS FOUND  12 ../customdata/]/space_352.jpg ]\n",
      "12  hands not found\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "def landmarks_to_csv():\n",
    "  mp_drawing = mp.solutions.drawing_utils\n",
    "  mp_drawing_styles = mp.solutions.drawing_styles\n",
    "  mp_hands = mp.solutions.hands\n",
    "  no_hand_count = 0\n",
    "\n",
    "  pics = []\n",
    "\n",
    "  DIR_SIZE = 500\n",
    "  ITERATION = 1\n",
    "\n",
    "  TRAIN_DIR = '../customdata/'\n",
    "\n",
    "  for dir in os.listdir(TRAIN_DIR):\n",
    "    ctr = 0\n",
    "    for img in os.listdir(TRAIN_DIR + dir):\n",
    "      if(ctr < DIR_SIZE):\n",
    "        if ctr % ITERATION == 0:\n",
    "          pics.append({TRAIN_DIR + dir + '/' + img:dir})\n",
    "          # print(TRAIN_DIR + dir + '/' + img)\n",
    "        ctr += 1\n",
    "\n",
    "  with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5) as hands:\n",
    "    \n",
    "    print('starting the long part...')\n",
    "\n",
    "    ctr = 0\n",
    "    for file in pics:\n",
    "      key = list(file.keys())[0]\n",
    "      val = list(file.values())[0]\n",
    "      if ctr % 1000 == 0:\n",
    "        print('dir', val, 'img', key)\n",
    "      ctr += 1\n",
    "      image = cv2.flip(cv2.imread(key), 1)\n",
    "      results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "      if not results.multi_hand_landmarks:\n",
    "        no_hand_count += 1\n",
    "        print('NO HANDS FOUND ', no_hand_count, key, val)\n",
    "        continue\n",
    "\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        landmark_list = landmark_list(image, hand_landmarks)\n",
    "        pre_processed_list = pre_process_landmark(landmark_list)\n",
    "        # print('logging', min(pre_processed_list))\n",
    "        csv(val, pre_processed_list)\n",
    "           \n",
    "\n",
    "  print(no_hand_count, ' hands not found')  \n",
    "  return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  landmarks_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c3f16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(r'keypoint.csv') as inputFile:\n",
    "    i = 0\n",
    "    x = csv.reader(inputFile)\n",
    "    with open(r'new4.csv','w', newline='') as outFile:\n",
    "        pass\n",
    "    for lines in x:\n",
    "        # print(lines)\n",
    "            # print(len(lines))\n",
    "            if len(lines) != 0 and len(lines[-1]) == 1:\n",
    "                lines[-1] = np.float64(ord(lines[-1]) - 65 - int(lines[-1]==']'))\n",
    "                with open(r'new4.csv','a', newline='') as outFile:\n",
    "                    iWrite = csv.writer(outFile, delimiter=',')\n",
    "                    iWrite.writerow(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f991ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "dataset = 'new4.csv'\n",
    "model_save_path = 'keypoint_classifier2.hdf5'\n",
    "\n",
    "test = X_dataset = np.loadtxt(dataset, delimiter=',')\n",
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(0, (21 * 2))))\n",
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=((21*2)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d492295",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(40, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dense(28, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(model_save_path, verbose=1, save_weights_only=False)\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00f05efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 3.2137 - accuracy: 0.1118\n",
      "Epoch 00001: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 3.2036 - accuracy: 0.1153 - val_loss: 2.8439 - val_accuracy: 0.2034\n",
      "Epoch 2/500\n",
      "88/88 [==============================] - ETA: 0s - loss: 2.6242 - accuracy: 0.2196\n",
      "Epoch 00002: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 2.6242 - accuracy: 0.2196 - val_loss: 1.9817 - val_accuracy: 0.3985\n",
      "Epoch 3/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 2.0930 - accuracy: 0.3332\n",
      "Epoch 00003: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 2.0616 - accuracy: 0.3409 - val_loss: 1.4299 - val_accuracy: 0.6293\n",
      "Epoch 4/500\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 1.7822 - accuracy: 0.4060\n",
      "Epoch 00004: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7798 - accuracy: 0.4076 - val_loss: 1.1541 - val_accuracy: 0.7438\n",
      "Epoch 5/500\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.5831 - accuracy: 0.4637\n",
      "Epoch 00005: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.5831 - accuracy: 0.4637 - val_loss: 0.9664 - val_accuracy: 0.8049\n",
      "Epoch 6/500\n",
      "87/88 [============================>.] - ETA: 0s - loss: 1.4618 - accuracy: 0.4976\n",
      "Epoch 00006: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.4621 - accuracy: 0.4969 - val_loss: 0.8618 - val_accuracy: 0.8292\n",
      "Epoch 7/500\n",
      "87/88 [============================>.] - ETA: 0s - loss: 1.3884 - accuracy: 0.5261\n",
      "Epoch 00007: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3878 - accuracy: 0.5264 - val_loss: 0.7961 - val_accuracy: 0.8428\n",
      "Epoch 8/500\n",
      "74/88 [========================>.....] - ETA: 0s - loss: 1.3354 - accuracy: 0.5359\n",
      "Epoch 00008: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3279 - accuracy: 0.5375 - val_loss: 0.7339 - val_accuracy: 0.8476\n",
      "Epoch 9/500\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 1.2900 - accuracy: 0.5472\n",
      "Epoch 00009: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2869 - accuracy: 0.5492 - val_loss: 0.7072 - val_accuracy: 0.8554\n",
      "Epoch 10/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 1.2479 - accuracy: 0.5625\n",
      "Epoch 00010: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.2449 - accuracy: 0.5643 - val_loss: 0.6693 - val_accuracy: 0.8594\n",
      "Epoch 11/500\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.2221 - accuracy: 0.5768\n",
      "Epoch 00011: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2221 - accuracy: 0.5768 - val_loss: 0.6570 - val_accuracy: 0.8524\n",
      "Epoch 12/500\n",
      "81/88 [==========================>...] - ETA: 0s - loss: 1.1880 - accuracy: 0.5832\n",
      "Epoch 00012: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.1911 - accuracy: 0.5824 - val_loss: 0.6273 - val_accuracy: 0.8690\n",
      "Epoch 13/500\n",
      "71/88 [=======================>......] - ETA: 0s - loss: 1.1746 - accuracy: 0.5849\n",
      "Epoch 00013: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.1737 - accuracy: 0.5851 - val_loss: 0.6016 - val_accuracy: 0.8727\n",
      "Epoch 14/500\n",
      "74/88 [========================>.....] - ETA: 0s - loss: 1.1437 - accuracy: 0.5946\n",
      "Epoch 00014: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.1447 - accuracy: 0.5945 - val_loss: 0.5786 - val_accuracy: 0.8815\n",
      "Epoch 15/500\n",
      "72/88 [=======================>......] - ETA: 0s - loss: 1.1264 - accuracy: 0.6048\n",
      "Epoch 00015: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.1292 - accuracy: 0.6031 - val_loss: 0.5733 - val_accuracy: 0.8906\n",
      "Epoch 16/500\n",
      "77/88 [=========================>....] - ETA: 0s - loss: 1.1250 - accuracy: 0.6073\n",
      "Epoch 00016: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.1229 - accuracy: 0.6064 - val_loss: 0.5565 - val_accuracy: 0.8855\n",
      "Epoch 17/500\n",
      "82/88 [==========================>...] - ETA: 0s - loss: 1.0891 - accuracy: 0.6068\n",
      "Epoch 00017: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.0904 - accuracy: 0.6084 - val_loss: 0.5532 - val_accuracy: 0.8932\n",
      "Epoch 18/500\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 1.0828 - accuracy: 0.6137\n",
      "Epoch 00018: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.0809 - accuracy: 0.6151 - val_loss: 0.5454 - val_accuracy: 0.9061\n",
      "Epoch 19/500\n",
      "86/88 [============================>.] - ETA: 0s - loss: 1.0740 - accuracy: 0.6215\n",
      "Epoch 00019: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.0725 - accuracy: 0.6219 - val_loss: 0.5268 - val_accuracy: 0.8884\n",
      "Epoch 20/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 1.0459 - accuracy: 0.6340\n",
      "Epoch 00020: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.0502 - accuracy: 0.6335 - val_loss: 0.5172 - val_accuracy: 0.8892\n",
      "Epoch 21/500\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0415 - accuracy: 0.6327\n",
      "Epoch 00021: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.0415 - accuracy: 0.6327 - val_loss: 0.5024 - val_accuracy: 0.8919\n",
      "Epoch 22/500\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0207 - accuracy: 0.6419\n",
      "Epoch 00022: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.0207 - accuracy: 0.6419 - val_loss: 0.4981 - val_accuracy: 0.9063\n",
      "Epoch 23/500\n",
      "74/88 [========================>.....] - ETA: 0s - loss: 1.0118 - accuracy: 0.6485\n",
      "Epoch 00023: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.0015 - accuracy: 0.6519 - val_loss: 0.4770 - val_accuracy: 0.8927\n",
      "Epoch 24/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 1.0050 - accuracy: 0.6414\n",
      "Epoch 00024: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.0039 - accuracy: 0.6440 - val_loss: 0.4833 - val_accuracy: 0.9079\n",
      "Epoch 25/500\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.9796 - accuracy: 0.6565\n",
      "Epoch 00025: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.9789 - accuracy: 0.6563 - val_loss: 0.4707 - val_accuracy: 0.9013\n",
      "Epoch 26/500\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9546 - accuracy: 0.6610\n",
      "Epoch 00026: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.9546 - accuracy: 0.6610 - val_loss: 0.4598 - val_accuracy: 0.9135\n",
      "Epoch 27/500\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.9663 - accuracy: 0.6554\n",
      "Epoch 00027: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.9673 - accuracy: 0.6547 - val_loss: 0.4518 - val_accuracy: 0.9090\n",
      "Epoch 28/500\n",
      "82/88 [==========================>...] - ETA: 0s - loss: 0.9613 - accuracy: 0.6590\n",
      "Epoch 00028: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.9597 - accuracy: 0.6592 - val_loss: 0.4530 - val_accuracy: 0.9063\n",
      "Epoch 29/500\n",
      "73/88 [=======================>......] - ETA: 0s - loss: 0.9422 - accuracy: 0.6598\n",
      "Epoch 00029: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.9421 - accuracy: 0.6607 - val_loss: 0.4478 - val_accuracy: 0.8978\n",
      "Epoch 30/500\n",
      "74/88 [========================>.....] - ETA: 0s - loss: 0.9517 - accuracy: 0.6651\n",
      "Epoch 00030: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.9467 - accuracy: 0.6668 - val_loss: 0.4463 - val_accuracy: 0.9170\n",
      "Epoch 31/500\n",
      "77/88 [=========================>....] - ETA: 0s - loss: 0.9187 - accuracy: 0.6745\n",
      "Epoch 00031: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.9224 - accuracy: 0.6729 - val_loss: 0.4339 - val_accuracy: 0.9050\n",
      "Epoch 32/500\n",
      "74/88 [========================>.....] - ETA: 0s - loss: 0.9247 - accuracy: 0.6702\n",
      "Epoch 00032: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.9252 - accuracy: 0.6705 - val_loss: 0.4397 - val_accuracy: 0.9199\n",
      "Epoch 33/500\n",
      "77/88 [=========================>....] - ETA: 0s - loss: 0.9018 - accuracy: 0.6847\n",
      "Epoch 00033: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.9090 - accuracy: 0.6802 - val_loss: 0.4224 - val_accuracy: 0.9146\n",
      "Epoch 34/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 0.8928 - accuracy: 0.6844\n",
      "Epoch 00034: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.8958 - accuracy: 0.6820 - val_loss: 0.4258 - val_accuracy: 0.9106\n",
      "Epoch 35/500\n",
      "74/88 [========================>.....] - ETA: 0s - loss: 0.9001 - accuracy: 0.6766\n",
      "Epoch 00035: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.8950 - accuracy: 0.6781 - val_loss: 0.4248 - val_accuracy: 0.9061\n",
      "Epoch 36/500\n",
      "79/88 [=========================>....] - ETA: 0s - loss: 0.8807 - accuracy: 0.6865\n",
      "Epoch 00036: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.8816 - accuracy: 0.6873 - val_loss: 0.4089 - val_accuracy: 0.9101\n",
      "Epoch 37/500\n",
      "77/88 [=========================>....] - ETA: 0s - loss: 0.8776 - accuracy: 0.6901\n",
      "Epoch 00037: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.8777 - accuracy: 0.6896 - val_loss: 0.4207 - val_accuracy: 0.9202\n",
      "Epoch 38/500\n",
      "79/88 [=========================>....] - ETA: 0s - loss: 0.8752 - accuracy: 0.6903\n",
      "Epoch 00038: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.8748 - accuracy: 0.6878 - val_loss: 0.4156 - val_accuracy: 0.9039\n",
      "Epoch 39/500\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 0.8564 - accuracy: 0.6930\n",
      "Epoch 00039: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.8579 - accuracy: 0.6931 - val_loss: 0.4019 - val_accuracy: 0.9058\n",
      "Epoch 40/500\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.8472 - accuracy: 0.6967\n",
      "Epoch 00040: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.8468 - accuracy: 0.6974 - val_loss: 0.3941 - val_accuracy: 0.9293\n",
      "Epoch 41/500\n",
      "75/88 [========================>.....] - ETA: 0s - loss: 0.8363 - accuracy: 0.7068\n",
      "Epoch 00041: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.8326 - accuracy: 0.7073 - val_loss: 0.3890 - val_accuracy: 0.9175\n",
      "Epoch 42/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 0.8307 - accuracy: 0.7058\n",
      "Epoch 00042: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.8237 - accuracy: 0.7063 - val_loss: 0.4067 - val_accuracy: 0.8978\n",
      "Epoch 43/500\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 0.8280 - accuracy: 0.7073\n",
      "Epoch 00043: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.8258 - accuracy: 0.7074 - val_loss: 0.3918 - val_accuracy: 0.9122\n",
      "Epoch 44/500\n",
      "81/88 [==========================>...] - ETA: 0s - loss: 0.8197 - accuracy: 0.7136\n",
      "Epoch 00044: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.8179 - accuracy: 0.7143 - val_loss: 0.3831 - val_accuracy: 0.9127\n",
      "Epoch 45/500\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.8010 - accuracy: 0.7117\n",
      "Epoch 00045: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.8024 - accuracy: 0.7114 - val_loss: 0.3803 - val_accuracy: 0.9263\n",
      "Epoch 46/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 0.7975 - accuracy: 0.7099\n",
      "Epoch 00046: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7958 - accuracy: 0.7102 - val_loss: 0.3882 - val_accuracy: 0.9231\n",
      "Epoch 47/500\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.8090 - accuracy: 0.7104\n",
      "Epoch 00047: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.8084 - accuracy: 0.7111 - val_loss: 0.3768 - val_accuracy: 0.9218\n",
      "Epoch 48/500\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 0.7930 - accuracy: 0.7166\n",
      "Epoch 00048: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.7940 - accuracy: 0.7167 - val_loss: 0.3797 - val_accuracy: 0.9301\n",
      "Epoch 49/500\n",
      "81/88 [==========================>...] - ETA: 0s - loss: 0.7789 - accuracy: 0.7269\n",
      "Epoch 00049: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7803 - accuracy: 0.7251 - val_loss: 0.3797 - val_accuracy: 0.9255\n",
      "Epoch 50/500\n",
      "81/88 [==========================>...] - ETA: 0s - loss: 0.7721 - accuracy: 0.7222\n",
      "Epoch 00050: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7701 - accuracy: 0.7236 - val_loss: 0.3744 - val_accuracy: 0.9290\n",
      "Epoch 51/500\n",
      "75/88 [========================>.....] - ETA: 0s - loss: 0.7678 - accuracy: 0.7272\n",
      "Epoch 00051: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7686 - accuracy: 0.7272 - val_loss: 0.3785 - val_accuracy: 0.9293\n",
      "Epoch 52/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 0.7674 - accuracy: 0.7287\n",
      "Epoch 00052: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7643 - accuracy: 0.7300 - val_loss: 0.3755 - val_accuracy: 0.9157\n",
      "Epoch 53/500\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.7412 - accuracy: 0.7339\n",
      "Epoch 00053: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.7392 - accuracy: 0.7347 - val_loss: 0.3596 - val_accuracy: 0.9378\n",
      "Epoch 54/500\n",
      "77/88 [=========================>....] - ETA: 0s - loss: 0.7294 - accuracy: 0.7395\n",
      "Epoch 00054: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7320 - accuracy: 0.7399 - val_loss: 0.3562 - val_accuracy: 0.9237\n",
      "Epoch 55/500\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.7493 - accuracy: 0.7309\n",
      "Epoch 00055: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.7481 - accuracy: 0.7314 - val_loss: 0.3610 - val_accuracy: 0.9189\n",
      "Epoch 56/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 0.7381 - accuracy: 0.7341\n",
      "Epoch 00056: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.7338 - val_loss: 0.3436 - val_accuracy: 0.9362\n",
      "Epoch 57/500\n",
      "75/88 [========================>.....] - ETA: 0s - loss: 0.7368 - accuracy: 0.7336\n",
      "Epoch 00057: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.7374 - val_loss: 0.3424 - val_accuracy: 0.9405\n",
      "Epoch 58/500\n",
      "75/88 [========================>.....] - ETA: 0s - loss: 0.7232 - accuracy: 0.7381\n",
      "Epoch 00058: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7307 - accuracy: 0.7383 - val_loss: 0.3535 - val_accuracy: 0.9295\n",
      "Epoch 59/500\n",
      "82/88 [==========================>...] - ETA: 0s - loss: 0.7138 - accuracy: 0.7438\n",
      "Epoch 00059: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.7154 - accuracy: 0.7431 - val_loss: 0.3300 - val_accuracy: 0.9410\n",
      "Epoch 60/500\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.7083 - accuracy: 0.7485\n",
      "Epoch 00060: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.7080 - accuracy: 0.7483 - val_loss: 0.3647 - val_accuracy: 0.9210\n",
      "Epoch 61/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 0.7016 - accuracy: 0.7501\n",
      "Epoch 00061: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7036 - accuracy: 0.7484 - val_loss: 0.3707 - val_accuracy: 0.9178\n",
      "Epoch 62/500\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.7012 - accuracy: 0.7507\n",
      "Epoch 00062: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.7506 - val_loss: 0.3539 - val_accuracy: 0.9322\n",
      "Epoch 63/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 0.6845 - accuracy: 0.7581\n",
      "Epoch 00063: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.7603 - val_loss: 0.3638 - val_accuracy: 0.9231\n",
      "Epoch 64/500\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.7555\n",
      "Epoch 00064: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.6880 - accuracy: 0.7555 - val_loss: 0.3546 - val_accuracy: 0.9285\n",
      "Epoch 65/500\n",
      "81/88 [==========================>...] - ETA: 0s - loss: 0.6924 - accuracy: 0.7528\n",
      "Epoch 00065: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.7540 - val_loss: 0.3645 - val_accuracy: 0.9245\n",
      "Epoch 66/500\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.6761 - accuracy: 0.7546\n",
      "Epoch 00066: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.6761 - accuracy: 0.7546 - val_loss: 0.3462 - val_accuracy: 0.9253\n",
      "Epoch 67/500\n",
      "81/88 [==========================>...] - ETA: 0s - loss: 0.7007 - accuracy: 0.7481\n",
      "Epoch 00067: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.7000 - accuracy: 0.7483 - val_loss: 0.3714 - val_accuracy: 0.9130\n",
      "Epoch 68/500\n",
      "73/88 [=======================>......] - ETA: 0s - loss: 0.6777 - accuracy: 0.7555\n",
      "Epoch 00068: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.7565 - val_loss: 0.3615 - val_accuracy: 0.9133\n",
      "Epoch 69/500\n",
      "80/88 [==========================>...] - ETA: 0s - loss: 0.6638 - accuracy: 0.7575\n",
      "Epoch 00069: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.7579 - val_loss: 0.3532 - val_accuracy: 0.9271\n",
      "Epoch 70/500\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.6490 - accuracy: 0.7653\n",
      "Epoch 00070: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.7641 - val_loss: 0.3477 - val_accuracy: 0.9295\n",
      "Epoch 71/500\n",
      "77/88 [=========================>....] - ETA: 0s - loss: 0.6517 - accuracy: 0.7685\n",
      "Epoch 00071: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6537 - accuracy: 0.7681 - val_loss: 0.3611 - val_accuracy: 0.9127\n",
      "Epoch 72/500\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 0.6310 - accuracy: 0.7770\n",
      "Epoch 00072: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.6307 - accuracy: 0.7771 - val_loss: 0.3486 - val_accuracy: 0.9237\n",
      "Epoch 73/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 0.6358 - accuracy: 0.7730\n",
      "Epoch 00073: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.7715 - val_loss: 0.3618 - val_accuracy: 0.9082\n",
      "Epoch 74/500\n",
      "73/88 [=======================>......] - ETA: 0s - loss: 0.6398 - accuracy: 0.7731\n",
      "Epoch 00074: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.7732 - val_loss: 0.3512 - val_accuracy: 0.9119\n",
      "Epoch 75/500\n",
      "81/88 [==========================>...] - ETA: 0s - loss: 0.6289 - accuracy: 0.7735\n",
      "Epoch 00075: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.7756 - val_loss: 0.3552 - val_accuracy: 0.9103\n",
      "Epoch 76/500\n",
      "76/88 [========================>.....] - ETA: 0s - loss: 0.6084 - accuracy: 0.7758\n",
      "Epoch 00076: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.6058 - accuracy: 0.7769 - val_loss: 0.3447 - val_accuracy: 0.9167\n",
      "Epoch 77/500\n",
      "73/88 [=======================>......] - ETA: 0s - loss: 0.6161 - accuracy: 0.7837\n",
      "Epoch 00077: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.7820 - val_loss: 0.3452 - val_accuracy: 0.9277\n",
      "Epoch 78/500\n",
      "74/88 [========================>.....] - ETA: 0s - loss: 0.5945 - accuracy: 0.7913\n",
      "Epoch 00078: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.7878 - val_loss: 0.3576 - val_accuracy: 0.9015\n",
      "Epoch 79/500\n",
      "81/88 [==========================>...] - ETA: 0s - loss: 0.6180 - accuracy: 0.7821\n",
      "Epoch 00079: saving model to keypoint_classifier2.hdf5\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.7828 - val_loss: 0.3629 - val_accuracy: 0.9122\n",
      "Epoch 00079: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d9fadbaeb0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=500,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b42c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLandmarks(img):\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_hands = mp.solutions.hands\n",
    "\n",
    "    image = cv2.imread(img)\n",
    "\n",
    "\n",
    "    with mp_hands.Hands(\n",
    "        model_complexity=0,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as hands:\n",
    "\n",
    "        results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            print(results.multi_hand_landmarks)\n",
    "            return results.multi_hand_landmarks[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0fd549f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000105A01BD5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "21\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# predicted_dataset = tf.convert_to_tensor([pre_processed_list])\n",
    "# predictions = model(predicted_dataset, training=False)\n",
    "\n",
    "# print(pre_processed_list)\n",
    "# print(X_test[0])\n",
    "\n",
    "# print(X_test[0])\n",
    "prediction = model.predict(np.array([pre_processed_list]))\n",
    "# prediction = model.predict(np.array([pre_processed_list]))\n",
    "# print(np.squeeze(prediction))\n",
    "print(np.argmax(np.squeeze(prediction)))\n",
    "print(y_test[0])\n",
    "# maxValue = max(prediction)\n",
    "# print(np.argmax(prediction), prediction[0][np.argmax(prediction)])\n",
    "\n",
    "\n",
    "# class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W','X','Y','Z']\n",
    "# for i, logits in enumerate(predictions):\n",
    "#   class_idx = tf.argmax(logits).numpy()\n",
    "#   p = tf.nn.softmax(logits)[class_idx]\n",
    "#   name = class_names[class_idx]\n",
    "#   print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c96d82b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fd954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the dataset file: C:\\Users\\ricky\\.keras\\datasets\\iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
    "                                           origin=train_dataset_url)\n",
    "\n",
    "print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04bccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['120', '4', 'setosa', 'versicolor', 'virginica', ' a']\n",
      "['6.4', '2.8', '5.6', '2.2', '2']\n",
      "['5.0', '2.3', '3.3', '1.0', '1']\n",
      "['4.9', '2.5', '4.5', '1.7', '2']\n",
      "['4.9', '3.1', '1.5', '0.1', '0']\n",
      "['5.7', '3.8', '1.7', '0.3', '0']\n",
      "['4.4', '3.2', '1.3', '0.2', '0']\n",
      "['5.4', '3.4', '1.5', '0.4', '0']\n",
      "['6.9', '3.1', '5.1', '2.3', '2']\n",
      "['6.7', '3.1', '4.4', '1.4', '1']\n",
      "['5.1', '3.7', '1.5', '0.4', '0']\n",
      "['5.2', '2.7', '3.9', '1.4', '1']\n",
      "['6.9', '3.1', '4.9', '1.5', '1']\n",
      "['5.8', '4.0', '1.2', '0.2', '0']\n",
      "['5.4', '3.9', '1.7', '0.4', '0']\n",
      "['7.7', '3.8', '6.7', '2.2', '2']\n",
      "['6.3', '3.3', '4.7', '1.6', '1']\n",
      "['6.8', '3.2', '5.9', '2.3', '2']\n",
      "['7.6', '3.0', '6.6', '2.1', '2']\n",
      "['6.4', '3.2', '5.3', '2.3', '2']\n",
      "['5.7', '4.4', '1.5', '0.4', '0']\n",
      "['6.7', '3.3', '5.7', '2.1', '2']\n",
      "['6.4', '2.8', '5.6', '2.1', '2']\n",
      "['5.4', '3.9', '1.3', '0.4', '0']\n",
      "['6.1', '2.6', '5.6', '1.4', '2']\n",
      "['7.2', '3.0', '5.8', '1.6', '2']\n",
      "['5.2', '3.5', '1.5', '0.2', '0']\n",
      "['5.8', '2.6', '4.0', '1.2', '1']\n",
      "['5.9', '3.0', '5.1', '1.8', '2']\n",
      "['5.4', '3.0', '4.5', '1.5', '1']\n",
      "['6.7', '3.0', '5.0', '1.7', '1']\n",
      "['6.3', '2.3', '4.4', '1.3', '1']\n",
      "['5.1', '2.5', '3.0', '1.1', '1']\n",
      "['6.4', '3.2', '4.5', '1.5', '1']\n",
      "['6.8', '3.0', '5.5', '2.1', '2']\n",
      "['6.2', '2.8', '4.8', '1.8', '2']\n",
      "['6.9', '3.2', '5.7', '2.3', '2']\n",
      "['6.5', '3.2', '5.1', '2.0', '2']\n",
      "['5.8', '2.8', '5.1', '2.4', '2']\n",
      "['5.1', '3.8', '1.5', '0.3', '0']\n",
      "['4.8', '3.0', '1.4', '0.3', '0']\n",
      "['7.9', '3.8', '6.4', '2.0', '2']\n",
      "['5.8', '2.7', '5.1', '1.9', '2']\n",
      "['6.7', '3.0', '5.2', '2.3', '2']\n",
      "['5.1', '3.8', '1.9', '0.4', '0']\n",
      "['4.7', '3.2', '1.6', '0.2', '0']\n",
      "['6.0', '2.2', '5.0', '1.5', '2']\n",
      "['4.8', '3.4', '1.6', '0.2', '0']\n",
      "['7.7', '2.6', '6.9', '2.3', '2']\n",
      "['4.6', '3.6', '1.0', '0.2', '0']\n",
      "['7.2', '3.2', '6.0', '1.8', '2']\n",
      "['5.0', '3.3', '1.4', '0.2', '0']\n",
      "['6.6', '3.0', '4.4', '1.4', '1']\n",
      "['6.1', '2.8', '4.0', '1.3', '1']\n",
      "['5.0', '3.2', '1.2', '0.2', '0']\n",
      "['7.0', '3.2', '4.7', '1.4', '1']\n",
      "['6.0', '3.0', '4.8', '1.8', '2']\n",
      "['7.4', '2.8', '6.1', '1.9', '2']\n",
      "['5.8', '2.7', '5.1', '1.9', '2']\n",
      "['6.2', '3.4', '5.4', '2.3', '2']\n",
      "['5.0', '2.0', '3.5', '1.0', '1']\n",
      "['5.6', '2.5', '3.9', '1.1', '1']\n",
      "['6.7', '3.1', '5.6', '2.4', '2']\n",
      "['6.3', '2.5', '5.0', '1.9', '2']\n",
      "['6.4', '3.1', '5.5', '1.8', '2']\n",
      "['6.2', '2.2', '4.5', '1.5', '1']\n",
      "['7.3', '2.9', '6.3', '1.8', '2']\n",
      "['4.4', '3.0', '1.3', '0.2', '0']\n",
      "['7.2', '3.6', '6.1', '2.5', '2']\n",
      "['6.5', '3.0', '5.5', '1.8', '2']\n",
      "['5.0', '3.4', '1.5', '0.2', '0']\n",
      "['4.7', '3.2', '1.3', '0.2', '0']\n",
      "['6.6', '2.9', '4.6', '1.3', '1']\n",
      "['5.5', '3.5', '1.3', '0.2', '0']\n",
      "['7.7', '3.0', '6.1', '2.3', '2']\n",
      "['6.1', '3.0', '4.9', '1.8', '2']\n",
      "['4.9', '3.1', '1.5', '0.1', '0']\n",
      "['5.5', '2.4', '3.8', '1.1', '1']\n",
      "['5.7', '2.9', '4.2', '1.3', '1']\n",
      "['6.0', '2.9', '4.5', '1.5', '1']\n",
      "['6.4', '2.7', '5.3', '1.9', '2']\n",
      "['5.4', '3.7', '1.5', '0.2', '0']\n",
      "['6.1', '2.9', '4.7', '1.4', '1']\n",
      "['6.5', '2.8', '4.6', '1.5', '1']\n",
      "['5.6', '2.7', '4.2', '1.3', '1']\n",
      "['6.3', '3.4', '5.6', '2.4', '2']\n",
      "['4.9', '3.1', '1.5', '0.1', '0']\n",
      "['6.8', '2.8', '4.8', '1.4', '1']\n",
      "['5.7', '2.8', '4.5', '1.3', '1']\n",
      "['6.0', '2.7', '5.1', '1.6', '1']\n",
      "['5.0', '3.5', '1.3', '0.3', '0']\n",
      "['6.5', '3.0', '5.2', '2.0', '2']\n",
      "['6.1', '2.8', '4.7', '1.2', '1']\n",
      "['5.1', '3.5', '1.4', '0.3', '0']\n",
      "['4.6', '3.1', '1.5', '0.2', '0']\n",
      "['6.5', '3.0', '5.8', '2.2', '2']\n",
      "['4.6', '3.4', '1.4', '0.3', '0']\n",
      "['4.6', '3.2', '1.4', '0.2', '0']\n",
      "['7.7', '2.8', '6.7', '2.0', '2']\n",
      "['5.9', '3.2', '4.8', '1.8', '1']\n",
      "['5.1', '3.8', '1.6', '0.2', '0']\n",
      "['4.9', '3.0', '1.4', '0.2', '0']\n",
      "['4.9', '2.4', '3.3', '1.0', '1']\n",
      "['4.5', '2.3', '1.3', '0.3', '0']\n",
      "['5.8', '2.7', '4.1', '1.0', '1']\n",
      "['5.0', '3.4', '1.6', '0.4', '0']\n",
      "['5.2', '3.4', '1.4', '0.2', '0']\n",
      "['5.3', '3.7', '1.5', '0.2', '0']\n",
      "['5.0', '3.6', '1.4', '0.2', '0']\n",
      "['5.6', '2.9', '3.6', '1.3', '1']\n",
      "['4.8', '3.1', '1.6', '0.2', '0']\n",
      "['6.3', '2.7', '4.9', '1.8', '2']\n",
      "['5.7', '2.8', '4.1', '1.3', '1']\n",
      "['5.0', '3.0', '1.6', '0.2', '0']\n",
      "['6.3', '3.3', '6.0', '2.5', '2']\n",
      "['5.0', '3.5', '1.6', '0.6', '0']\n",
      "['5.5', '2.6', '4.4', '1.2', '1']\n",
      "['5.7', '3.0', '4.2', '1.2', '1']\n",
      "['4.4', '2.9', '1.4', '0.2', '0']\n",
      "['4.8', '3.0', '1.4', '0.1', '0']\n",
      "['5.5', '2.4', '3.7', '1.0', '1']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(train_dataset_fp) as inputFile:\n",
    "    i = 0\n",
    "    x = csv.reader(inputFile)\n",
    "    for lines in x:\n",
    "        print(lines)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Problem inferring types: CSV row 2 has 6 number of fields. Expected: 5.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6740/1236734857.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mcolumn_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mlabel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     num_epochs=1)\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\readers.py\u001b[0m in \u001b[0;36mmake_csv_dataset_v2\u001b[1;34m(file_pattern, batch_size, column_names, column_defaults, label_name, select_columns, field_delim, use_quote_delim, na_value, header, num_epochs, shuffle, shuffle_buffer_size, shuffle_seed, prefetch_buffer_size, num_parallel_reads, sloppy, num_rows_for_inference, compression_type, ignore_errors)\u001b[0m\n\u001b[0;32m    542\u001b[0m                                              \u001b[0mna_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m                                              \u001b[0mnum_rows_for_inference\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                                              select_columns, file_io_fn)\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mselect_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_defaults\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\readers.py\u001b[0m in \u001b[0;36m_infer_column_defaults\u001b[1;34m(filenames, num_cols, field_delim, use_quote_delim, na_value, header, num_rows_for_inference, select_columns, file_io_fn)\u001b[0m\n\u001b[0;32m    142\u001b[0m   for i, csv_row in enumerate(\n\u001b[0;32m    143\u001b[0m       _next_csv_row(filenames, num_cols, field_delim, use_quote_delim, header,\n\u001b[1;32m--> 144\u001b[1;33m                     file_io_fn)):\n\u001b[0m\u001b[0;32m    145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_rows_for_inference\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mnum_rows_for_inference\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m       \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\readers.py\u001b[0m in \u001b[0;36m_next_csv_row\u001b[1;34m(filenames, num_cols, field_delim, use_quote_delim, header, file_io_fn)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_row\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m           raise ValueError(\n\u001b[1;32m--> 128\u001b[1;33m               \u001b[1;34mf\"Problem inferring types: CSV row {row_num} has {len(csv_row)} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m               f\"number of fields. Expected: {num_cols}.\")\n\u001b[0;32m    130\u001b[0m         \u001b[0mrow_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Problem inferring types: CSV row 2 has 6 number of fields. Expected: 5."
     ]
    }
   ],
   "source": [
    "# column order in CSV file\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1)\n",
    "\n",
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features)\n",
    "\n",
    "import csv\n",
    "with open(train_dataset_fp) as inputFile:\n",
    "    i = 0\n",
    "    x = csv.reader(inputFile)\n",
    "    for lines in x:\n",
    "        print(lines)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d2d3df81557cb0f713577f381e2a284343e4ea3fb6b75ccb2749796ea442f64"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
